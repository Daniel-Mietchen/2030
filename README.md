# About
A collection of thoughts on how science communication might (or should) look like in 2030. They arise from a meeting on the matter in spring 2015, in the preparation for which views were thought on how the world might then look like for specific groups of stakeholders, namely for researchers, research performing organisations/ universities, research funding organisation, publishers.

# Long-term vision for research

* What would science look like if it were invented today? (from 2009)
  * [Part 1](http://ways.org/en/blogs/2009/jun/29/what_would_science_look_like_if_it_were_invented_today)
  * [Part 2](http://ways.org/en/blogs/2009/sep/29/what_would_science_look_like_if_it_were_invented_today_part_ii_knowledge_structuring)
* Video: [Open research](https://www.youtube.com/watch?v=LwW1-X3glak)

# General remarks

* These four stakeholder groups are already not representative of the relevant communities; perhaps much less so in 2030.

* boundaries between these stakeholder groups are increasingly going to blur

* contributions to infrastructure and sustaining communities need to become more international

* We need to think more in terms of workflows, less in terms of individual snapshots thereof, and (re)build institutions, policies, funding mechanisms, careers, training and publishing etc. around that.

* Version control is built in to virtually all aspects of research, and version histories are being exposed by default

* The current cacophony of communication channels must be complemented by more standardized mechanisms for being notified of changes in a given field.

* find the right balance in terms of acknowledging the contributions of
individuals, institutions

* openness comes with new requirements for attribution

* gamifying/ personalizing education, health etc.

* Research needs to be much more aligned with societal needs, and make society aware of that.

* Policies and procedures that are needed to foster Open Science were missing in the picture of “Barriers and incentives to foster Open Science/ Research infrastructures to develop and sustain Open Science/ Socio-economic drivers to support Open Science”. Policies come top down and bottom up. Top down are harder to get buy-in but potentially
more profound in the long-term e.g. [M1313](https://www.whitehouse.gov/sites/default/files/omb/memoranda/2013/m-13-13.pdf) and the [Holdren memo](https://www.whitehouse.gov/sites/default/files/microsites/ostp/ostp_public_access_memo_2013.pdf) in the US. Bottom up are driven by the community and as such usually are supported by the community although sustaining them can be an issue.

* Policies have to be more closely linked to the technical aspects of their implementation. Example: when issuing data sharing mandates, make their essential components and those of data management plans machine readable, such that (a) compliance can be monitored, (b) community can be notified when new plans or datasets are being
published, thereby also fostering post-publication peer review.



# Specific notes on individual stakeholder groups

## Researchers

* research workflows will be more digital and shared to a much greater extent

* broader definition of researchers, to include citizen scientists,
patients and other non-institutional researchers of diverse
backgrounds, not necessarily with a formal research-related education

* while on-site work will likely still be the dominant mode of work
for lab-based researchers, they will work remotely more often. For
most other researchers, remote is likely going to be the default.

* meetings and other forms of community interactions will have
stronger online components than they do now

* openness has side effects, e.g. new modes of finding collaborators
and of collaboration more generally, including more instances of
"someone else solved my problem while I was asleep"


## Research performing organisation/ university

* need to redefine identity in light of web-based workflows,
digitized content, remote work et al., in conjunction with related
activities like online coursework

* need to adapt assessment mechanisms to Web age, e.g. by valuing
various research outputs way beyond classical papers, including
contributions to open-science/ citizen science projects by others


## Research funding organisation

* increasing demands of openness on the part of funded researchers,
projects, institutions

* piggybacking on that, increasing demands on openness of the funding
process and on assessing the efficiency of funding mechanisms

* have to realize that research is a global endeavour, and adjust
funding mechanisms and related activities (e.g. outreach, red tape)
accordingly

* adapt assessment mechanisms to the Web age, as outlined for
research institutions above

* (wishful thinking): sustainable funding modes for researchers,
infrastructure, communities


## Publishers

* have to provide real added value, e.g. helping with navigating the
flood of research information that is being made public

* have to get ever closer to publishing research workflows, rather
than just snapshots of outputs

* favour post-publication peer review instead of pre-publication peer
review, and public over non-public peer review

# Notes from the meeting

* scenarios
  * someone else did it while i was asleep
  * kid sends me inquiry about my work
* teaching science by doing it in the open

* "don’t want to see the raw data before official publication"
  * does not work if there is a deadline
		  * disaster response
		  * cancer et al

* "information overflow"
  * let machines do some pre-filtering	
  * go for machine readability, e.g. of data management plans, to enable sharing/ subscriptions/ alerts for specific publishing events

* Researchers spend much of their time writing and reviewing grant proposals and/ or papers, which takes away time from actually doing research. Many of these proposals and papers end up being rejected, so the time spent on them is somewhat wasted. Let's reduce this amount of waste.

* revision scoring

* platforms

* federated approach, e.g. federated wiki, Diaspora

* comparison with sports
  * performing research in a stadium, e.g. Otto von Guericke's [Magdeburg hemispheres](https://en.wikipedia.org/wiki/Magdeburg_hemispheres)
  * some 2009/2010 blog posts on funding:
    * [How would you fund science?](http://ways.org/en/blogs/2010/mar/15/how_would_you_fund_science) 
    * [Implementing Fantasy Science Funding](http://ways.org/en/blogs/2009/may/24/implementing_fantasy_science_funding)
    * [Fair play in academia - a test of the efficiency of non-public peer review](http://ways.org/en/blogs/2010/mar/15/fair_play_in_academia_a_test_of_the_efficiency_of_nonpublic_peer_review)

* open science as a tool for education

* baseline funding

* "call for ideas, call for solutions”
  * more emphasis on prizes, challenges


* diversification of the funders community:
  * classical funders
  * researchers have part of their budget that they can spend on research performed _by others_
  * the public at large (crowdfunding)
  * corporate social responsibility

* every open proposal is a call for funders and collaborators

* foster experimentation, e.g. with public peer review or random elements

* consider societal impact of past and proposed research


* publishers need to publish workflows

* overlay journals, add value by filtering published information

* publish in a way that allows to aggregate knowledge by topic rather than brand

* peer review does not have to take place before publication, but is essential and can be very useful thereafter

* internet of things; DOI for everything


